{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Please_work.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqMrVqwR2BmsNguB43r6po",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benjamin-Menashe/courses/blob/master/Copy_of_Please_work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import matplotlib as plt\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "np.random.seed(123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-5S13Z5EWnD",
        "outputId": "b608bd5e-1b85-4d08-da03-6c267d69f48f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.read_csv(\"drive/MyDrive/Colab_Notebooks/NN_project/Clean_3.csv\")\n",
        "sub_list = x['Participant_ID'].unique()"
      ],
      "metadata": {
        "id": "hIBwK7zsEZV9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt = torch.zeros(55*84, 60, 32)\n",
        "j = 0\n",
        "\n",
        "for i in sub_list:\n",
        "  for t in range(1,56):\n",
        "    cur = x.query(f\"Participant_ID == '{i}' & Text_ID=={t}\").filter(items=['Word_Length','Syl','CV_Complexity','Content','Noun','Verb','Adjective','Preposition','Article','Adverb','Pronoun','Determiner','Conjunction','Certainty','LSA_Context_Score','IA_AREA_Z','Freq','Orth','Orth_F','N1_F','N1_C','N2_F','N2_C','N3_F','N3_C','UN1_F','UN1_C','UN2_F','UN2_C','UN3_F','UN3_C','IA_FIXATION'])\n",
        "    # cur = x.query(f\"Participant_ID == '{i}' & Text_ID=={t}\").filter(items=['Word_Length','Content','LSA_Context_Score','IA_FIXATION'])\n",
        "    dt[j,:len(cur),:] = torch.tensor(cur.values).reshape(1,len(cur),32)\n",
        "    j += 1\n"
      ],
      "metadata": {
        "id": "p861mr__Edj_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = dt[:,:,0:31]\n",
        "y = dt[:,:,31].reshape(4620,60,1)"
      ],
      "metadata": {
        "id": "2SY6kjY1E5Yt"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.nan_to_num()\n",
        "y = y.nan_to_num()"
      ],
      "metadata": {
        "id": "jkvySKmfQpwa"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "rnning"
      ],
      "metadata": {
        "id": "Jd_nOAQCGudf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "LN2XKaAhGwON"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = TensorDataset(x[0:3700,:,:],y[0:3700,:,:])\n",
        "test = TensorDataset(x[3700:,:,:],y[3700:,:,:])"
      ],
      "metadata": {
        "id": "2bSpGHlMF8_5"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VanillaRNN(nn.Module):\n",
        "    def __init__(self, batch_size, input_size, hidden_size, output_size):\n",
        "        super(VanillaRNN, self).__init__()\n",
        "        self.batch_size, self.input_size, self.hidden_size, self.output_size = batch_size, input_size, hidden_size, output_size\n",
        "        \n",
        "        # RNN Layer\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=5, nonlinearity='relu')\n",
        "        # Fully Connected Layer\n",
        "        self.layer = nn.Linear(hidden_size, self.output_size)\n",
        "        # Sigmoid\n",
        "        self.layer2 = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, texts, prints=False):\n",
        "        if prints: print('Original Texts Shape:', texts.shape)\n",
        "        \n",
        "        # Initialize hidden state with zeros\n",
        "        hidden_state = torch.zeros(5, self.batch_size, self.hidden_size)\n",
        "        if prints: print('Initial hidden state Shape:', hidden_state.shape)\n",
        "        \n",
        "        # Creating RNN\n",
        "        hidden_outputs, hidden_state = self.rnn(texts, hidden_state)\n",
        "        \n",
        "        # \n",
        "        mid = self.layer(hidden_outputs.detach())\n",
        "        out = self.layer2(mid)\n",
        "        \n",
        "        if prints:\n",
        "            print('----hidden_outputs shape:', hidden_outputs.shape, '\\n' +\n",
        "                  '----final hidden state:', hidden_state.shape, '\\n' +\n",
        "                  '----out shape:', out.shape)\n",
        "        \n",
        "        if prints: print('Out Final Shape:', out.shape)\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "5x1LiQ-HG-Mg"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train, batch_size=64)"
      ],
      "metadata": {
        "id": "xjcw4JUtHkRi"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== STATICS ====\n",
        "batch_size = 64        # how many images to be trained in one iteration\n",
        "input_size = 31        # \n",
        "hidden_size = 100      # can be changed to any number: neurons\n",
        "output_size = 1       # \n",
        "# =================\n",
        "\n",
        "# Select one full batch from the data\n",
        "texts_example, labels_example = next(iter(train_loader))\n",
        "texts_example = texts_example.transpose(0,1)\n",
        "print('original texts shape:', texts_example.shape)\n",
        "\n",
        "model_example = VanillaRNN(batch_size, input_size, hidden_size, output_size)\n",
        "\n",
        "out = model_example(texts_example, prints=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrUGz7diHMfK",
        "outputId": "53ad1d3e-4e05-4614-f423-2e49bab927ad"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original texts shape: torch.Size([60, 64, 31])\n",
            "Original Texts Shape: torch.Size([60, 64, 31])\n",
            "Initial hidden state Shape: torch.Size([4, 64, 100])\n",
            "----hidden_outputs shape: torch.Size([60, 64, 100]) \n",
            "----final hidden state: torch.Size([4, 64, 100]) \n",
            "----out shape: torch.Size([60, 64, 1])\n",
            "Out Final Shape: torch.Size([60, 64, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(out, actual_labels, batchSize):\n",
        "    predictions = out.round()\n",
        "    correct = (predictions == actual_labels).sum().item()\n",
        "    accuracy = correct/batch_size\n",
        "    \n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "_-x9SGWxNlIN"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_network(model, train_data, test_data, batchSize=64, num_epochs=1, learning_rate=0.01):\n",
        "    \n",
        "    '''Trains the model and computes the average accuracy for train and test data.'''\n",
        "    \n",
        "    print('Get data ready...')\n",
        "    # Create dataloader for training dataset - so we can train on multiple batches\n",
        "    # Shuffle after every epoch\n",
        "    train_loader = DataLoader(dataset=train_data, batch_size=batchSize, shuffle=True, drop_last=True)\n",
        "    test_loader = DataLoader(dataset=test_data, batch_size=batchSize, shuffle=True, drop_last=True)\n",
        "    \n",
        "    # Create criterion and optimizer\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)    \n",
        "    \n",
        "    print('Training started...')\n",
        "    # Train the data multiple times\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        # Save Train and Test Loss\n",
        "        train_loss = 0\n",
        "        train_acc = 0\n",
        "        \n",
        "        # Set model in training mode:\n",
        "        model.train()\n",
        "        \n",
        "        for k, (texts, labels) in enumerate(train_loader):\n",
        "            \n",
        "            # reshape\n",
        "            texts = texts.transpose(0,1)\n",
        "            labels = labels.transpose(0,1)\n",
        "\n",
        "            # Create outputs\n",
        "            out = model(texts)\n",
        "            # Clears the gradients from previous iteration\n",
        "            optimizer.zero_grad()\n",
        "            # Computes loss: how far is the prediction from the actual?\n",
        "            loss = criterion(out, labels)\n",
        "            # Computes gradients for neurons\n",
        "            loss.backward()\n",
        "            # Updates the weights\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Save Loss & Accuracy after each iteration\n",
        "            train_loss += loss.item()\n",
        "            train_acc += get_accuracy(out, labels, batchSize)\n",
        "            \n",
        "        \n",
        "        # Print Average Train Loss & Accuracy after each epoch\n",
        "        print('TRAIN | Epoch: {}/{} | Loss: {:.2f} | Accuracy: {:.2f}'.format(epoch+1, num_epochs, train_loss/k, train_acc/k))\n",
        "            \n",
        "            \n",
        "    print('Testing Started...')\n",
        "    # Save Test Accuracy\n",
        "    test_acc = 0\n",
        "    # Evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    for k, (texts, labels) in enumerate(test_loader):\n",
        "        \n",
        "        # reshape\n",
        "        texts = texts.transpose(0,1)\n",
        "        labels = labels.transpose(0,1)\n",
        "\n",
        "        # Create = predictions\n",
        "        out = model(texts)\n",
        "        # Add Accuracy of this batch\n",
        "        test_acc += get_accuracy(out, labels, batchSize)\n",
        "        \n",
        "    # Print Final Test Accuracy\n",
        "    print('TEST | Average Accuracy per {} Loaders: {:.5f}'.format(k, test_acc/k) )"
      ],
      "metadata": {
        "id": "z-WWwFSnNwSK"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== STATICS ====\n",
        "batch_size=64\n",
        "input_size=31\n",
        "hidden_size=150\n",
        "output_size=1\n",
        "\n",
        "# Instantiate the model\n",
        "vanilla_rnn = VanillaRNN(batch_size, input_size, hidden_size, output_size)\n",
        "\n",
        "# ==== TRAIN ====\n",
        "train_network(vanilla_rnn, train, test, num_epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "NxUwZZIvN9qU",
        "outputId": "9b744a41-ec7c-4b1c-b34e-71319ad3b88d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get data ready...\n",
            "Training started...\n",
            "TRAIN | Epoch: 1/100 | Loss: 0.28 | Accuracy: 44.50\n",
            "TRAIN | Epoch: 2/100 | Loss: 0.27 | Accuracy: 44.91\n",
            "TRAIN | Epoch: 3/100 | Loss: 0.27 | Accuracy: 44.91\n",
            "TRAIN | Epoch: 4/100 | Loss: 0.27 | Accuracy: 44.92\n",
            "TRAIN | Epoch: 5/100 | Loss: 0.28 | Accuracy: 44.55\n",
            "TRAIN | Epoch: 6/100 | Loss: 0.27 | Accuracy: 44.82\n",
            "TRAIN | Epoch: 7/100 | Loss: 0.27 | Accuracy: 44.93\n",
            "TRAIN | Epoch: 8/100 | Loss: 0.27 | Accuracy: 44.91\n",
            "TRAIN | Epoch: 9/100 | Loss: 0.27 | Accuracy: 44.91\n",
            "TRAIN | Epoch: 10/100 | Loss: 0.27 | Accuracy: 44.89\n",
            "TRAIN | Epoch: 11/100 | Loss: 0.27 | Accuracy: 44.92\n",
            "TRAIN | Epoch: 12/100 | Loss: 0.27 | Accuracy: 44.91\n",
            "TRAIN | Epoch: 13/100 | Loss: 0.27 | Accuracy: 44.91\n",
            "TRAIN | Epoch: 14/100 | Loss: 0.27 | Accuracy: 44.91\n",
            "TRAIN | Epoch: 15/100 | Loss: 0.27 | Accuracy: 44.91\n",
            "TRAIN | Epoch: 16/100 | Loss: 0.27 | Accuracy: 44.91\n",
            "TRAIN | Epoch: 17/100 | Loss: 0.27 | Accuracy: 44.90\n",
            "TRAIN | Epoch: 18/100 | Loss: 0.27 | Accuracy: 44.92\n",
            "TRAIN | Epoch: 19/100 | Loss: 0.27 | Accuracy: 44.94\n",
            "TRAIN | Epoch: 20/100 | Loss: 0.27 | Accuracy: 44.88\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-65b2a76491be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# ==== TRAIN ====\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvanilla_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-55-6111c7aace6e>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(model, train_data, test_data, batchSize, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# Create outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Clears the gradients from previous iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-86b33a520839>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, texts, prints)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Creating RNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mhidden_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 269\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlILwApJNk6f",
        "outputId": "f6169e4a-8332-4116-970a-93b02fa064ad"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.4876],\n",
              "         [0.4876],\n",
              "         [0.4876],\n",
              "         ...,\n",
              "         [0.4876],\n",
              "         [0.4876],\n",
              "         [0.4876]],\n",
              "\n",
              "        [[0.4913],\n",
              "         [0.4913],\n",
              "         [0.4913],\n",
              "         ...,\n",
              "         [0.4913],\n",
              "         [0.4913],\n",
              "         [0.4913]],\n",
              "\n",
              "        [[0.4918],\n",
              "         [0.4918],\n",
              "         [0.4918],\n",
              "         ...,\n",
              "         [0.4918],\n",
              "         [0.4918],\n",
              "         [0.4918]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.4923],\n",
              "         [0.4923],\n",
              "         [0.4923],\n",
              "         ...,\n",
              "         [0.4923],\n",
              "         [0.4923],\n",
              "         [0.4923]],\n",
              "\n",
              "        [[0.4923],\n",
              "         [0.4923],\n",
              "         [0.4923],\n",
              "         ...,\n",
              "         [0.4923],\n",
              "         [0.4923],\n",
              "         [0.4923]],\n",
              "\n",
              "        [[0.4923],\n",
              "         [0.4923],\n",
              "         [0.4923],\n",
              "         ...,\n",
              "         [0.4923],\n",
              "         [0.4923],\n",
              "         [0.4923]]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}